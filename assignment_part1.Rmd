---
title: "Exponential distribution analysis"
author: "Pier Lorenzo Paracchini"
output:
  word_document:
    fig_height: 3
    fig_width: 4
  html_document:
    fig_width: 7.5
    keep_md: yes
---
```{r settingsAndDependencies, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
Sys.setlocale("LC_ALL", "C")
require(ggplot2)
set.seed(19711004)
```
##Overview
The Central Limit Theorem (CLT) states that _"the distribution of averages of indipendent and identically distributed (iid) variables becomes that of a standard normal as the sample size increase."_  so in this assignment it will be investigate the behaviour of the __exponential distribution__ when looking at the distribution of averages of 40 exponentials (and more).  

##Simulations 
Let´s simulate an experiment with a random variable $X$ with an __exponential distribution__ with the following characteristics

* __rate parameter__ $\lambda = 0.2$ 
    * __mean__ $\mu = E[X_i] = 1/\lambda = 5$
    * __standard deviation__ $\sigma = \sqrt[2]{xVar(X_i)} = 1/\lambda = 5$
    * __standard error__ (SE) $\sigma/\sqrt[2]{n}$

For building the distribution of averages we will run thousands of simulation and for each simulation the following steps are executed:

* run the experiment $n$ time where `n = 40, 80, 120, 160`,
    * be $X_i$ the outcome for the experiment $i =1..n$.
* calculate the mean $\bar X_n$ using $X_1, X_2, .., X_40$ 
* calculate $\frac{\bar X_n - \mu}{\sigma / \sqrt{n}}$

The following the code snippet can be used to generate the simulation data.

```{r simulationCode}
nosim = 1000
n = 40
clt_func <- function(x, n) sqrt(n) * (mean(x) - 5) / 5

dat <- data.frame(
  x = c(
    apply(matrix(rexp(n * nosim, 0.2), nrow = nosim), MARGIN = 1, clt_func, n),
    apply(matrix(rexp((2*n) * nosim, 0.2), nrow = nosim), MARGIN = 1, clt_func, (2*n)),
    apply(matrix(rexp((3*n) * nosim, 0.2), nrow = nosim), MARGIN = 1, clt_func, (3*n)),
    apply(matrix(rexp((4*n) * nosim, 0.2), nrow = nosim), MARGIN = 1, clt_func, (4*n))
    ),
  size = factor(rep(c(n, 2*n, 3*n, 4*n), rep(nosim, 4)))
  )
```


##Sample Mean versus Theoretical Mean 
Based on the __CLT__ the __theoretical mean__ is $\mu=0$ and the value of the sample mean is __`r mean(dat[dat$size == 40,]$x)`__ for n = 40. The __sample mean__ is around the __theoretical mean__ for `n = 40` and it converges more and more to it increasing the size of n (`n = 80, 120, 160`). 

```{r ref.label="meanDetails", echo=FALSE, fig.height=3, fig.width=6}
```

##Sample Variance versus Theoretical Variance
Based on the __CLT__ the __theoretical variance__ is $\sigma^2=1$ and the value of the sample variance is __`r sd(dat[dat$size == 40,]$x)^2`__ for n = 40. The __sample variance__ is around the __theoretical variance__ for `n = 40` and it converges more and more to it increasing the size of n (`n = 80, 120, 160`). 

```{r ref.label="varianceDetails", echo=FALSE, fig.height=3, fig.width=6}
```

##Distribution
Let´s plot the distribution of the averages previously calculated over all of the simulations together with the standard normal distribution $N(0,1)$. We can see from the plot below, the distribution of averages ($\frac{\bar X_n - \mu}{\sigma / \sqrt{n}}$) is a good approximation of a standard normal distribution $N(0,1)$  (black curve) as expected from the Central Limit Theorem.

```{r ref.label="plotGeneration", message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=9}
```

##Appendix

Code chunk used to generate plot in __Sample Mean versus Theoretical Mean__ section. 

```{r meanDetails, echo=TRUE, fig.height=3, fig.width=6}
meanSims <- c(
    mean(dat[dat$size == n,]$x), 
    mean(dat[dat$size == (2*n),]$x), 
    mean(dat[dat$size == (3*n),]$x), 
    mean(dat[dat$size == (4*n),]$x)
    )
g <- ggplot(data.frame(x = c(n, 2*n, 3*n, 4*n), y = meanSims), aes(x = x, y = y)) 
g <- g + geom_hline(yintercept = 0, color = "red") + geom_line(size = 1) + geom_point(shape = 5, size = 3) 
g <- g + labs(x = "n", y = "Mean", title ="Sample Mean(black) vs. Theoretical Mean(red)")
g <- g + coord_cartesian(xlim= c(20,170), ylim=c(-0.06,0.06))
g
```

Code chunk used to generate plot in __Sample Variance versus Theoretical Variance__ section. 

```{r varianceDetails, echo=TRUE, fig.height=3, fig.width=6}
varianceSims <- c(
    sd(dat[dat$size == n,]$x)^2, 
    sd(dat[dat$size == (2*n),]$x)^2, 
    sd(dat[dat$size == (3*n),]$x)^2, 
    sd(dat[dat$size == (4*n),]$x)^2
    )
g <- ggplot(data.frame(x = c(n, 2*n, 3*n, 4*n), y = varianceSims), aes(x = x, y = y)) 
g <- g + geom_hline(yintercept = 1, color = "red") + geom_line(size = 1) + geom_point(shape = 5, size = 3) 
g <- g + labs(x = "n", y = "Variance", title ="Sample Variance(black) vs. Theoretical Variance(red)")
g <- g + coord_cartesian(xlim= c(20,170), ylim=c(0.9,1.1))
g
```

Code chunk used to generate plot in __Distribution__ section. 

```{r plotGeneration, echo=TRUE, fig.height=5, fig.width=9}
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..)) 
g <- g + stat_function(fun = dnorm, size = 0.8)
g <- g + geom_vline(xintercept=c(0,0), color="black", linetype="dotted", size = 0.8)
g <- g + coord_cartesian(xlim= c(-3.1,3.1)) + labs(title = "Distribution of averages of (size) exponentials")
g + facet_grid(. ~ size)
```